{
  "name": "Model Training Workflow",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "train-model",
        "options": {}
      },
      "id": "5827b10d-bc97-48ae-9b09-0910b8f8c0c4",
      "name": "Webhook",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [
        250,
        300
      ]
    },
    {
      "parameters": {
        "jsCode": "// Parse the input\nconst table_name = $input.body.table_name;\nconst feature_column = $input.body.feature_column;\nconst label_column = $input.body.label_column;\nconst model_type = $input.body.model_type || 'classifier';\nconst model_id = $input.body.model_id;\nconst model_params = $input.body.model_params || {};\nconst lancedb_path = $input.body.lancedb_path;\nconst models_dir = $input.body.models_dir;\n\n// Import required modules\nconst lancedb = require('lancedb');\nconst fs = require('fs');\nconst path = require('path');\nconst { v4: uuidv4 } = require('uuid');\nconst { exec } = require('child_process');\n\n// Helper function to run Python code for model training\nasync function trainWithPython(data, model_type, model_params) {\n  return new Promise((resolve, reject) => {\n    // Write data to temporary file\n    const tempDataFile = path.join('./temp', `training_data_${Date.now()}.json`);\n    fs.writeFileSync(tempDataFile, JSON.stringify(data));\n    \n    // Generate Python script for training\n    const pythonScript = `\nimport sys\nimport json\nimport numpy as np\nimport pickle\nfrom sklearn.model_selection import train_test_split\n\n# Load data\nwith open('${tempDataFile}', 'r') as f:\n    data = json.load(f)\n\n# Extract features and labels\nX = np.array([row['features'] for row in data])\ny = np.array([row['label'] for row in data])\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create and train model\nif '${model_type}' == 'classifier':\n    from sklearn.ensemble import RandomForestClassifier\n    model = RandomForestClassifier(**${JSON.stringify(model_params)})\nelif '${model_type}' == 'regressor':\n    from sklearn.ensemble import RandomForestRegressor\n    model = RandomForestRegressor(**${JSON.stringify(model_params)})\nelse:\n    sys.exit('Unsupported model type: ${model_type}')\n\n# Train the model\nmodel.fit(X_train, y_train)\n\n# Evaluate the model\npredictions = model.predict(X_test)\n\n# Calculate metrics\nmetrics = {}\nif '${model_type}' == 'classifier':\n    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
    metrics = {
        'accuracy': float(accuracy_score(y_test, predictions)),
        'precision': float(precision_score(y_test, predictions, average='macro', zero_division=0)),
        'recall': float(recall_score(y_test, predictions, average='macro', zero_division=0)),
        'f1': float(f1_score(y_test, predictions, average='macro', zero_division=0)),
    }
elif '${model_type}' == 'regressor':
    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
    metrics = {
        'mse': float(mean_squared_error(y_test, predictions)),
        'rmse': float(np.sqrt(mean_squared_error(y_test, predictions))),
        'mae': float(mean_absolute_error(y_test, predictions)),
        'r2': float(r2_score(y_test, predictions)),
    }

# Calculate mean of feature vectors as model representation
model_vector = np.mean(X, axis=0).tolist()

# Save the model
model_file = '${path.join('./temp', `model_${Date.now()}.pkl`)}'
with open(model_file, 'wb') as f:
    pickle.dump(model, f)

# Output results
result = {
    'metrics': metrics,
    'model_file': model_file,
    'model_vector': model_vector
}
with open('${path.join('./temp', `results_${Date.now()}.json`)}', 'w') as f:
    json.dump(result, f)
`;\n    \n    // Write Python script to file\n    const scriptFile = path.join('./temp', `train_script_${Date.now()}.py`);\n    fs.writeFileSync(scriptFile, pythonScript);\n    \n    // Execute Python script\n    exec(`python ${scriptFile}`, (error, stdout, stderr) => {\n      if (error) {\n        console.error(`Execution error: ${error}`);\n        reject(error);\n        return;\n      }\n      \n      if (stderr) {\n        console.error(`Python stderr: ${stderr}`);\n      }\n      \n      // Read results\n      const resultsFile = glob.sync(path.join('./temp', 'results_*.json'))[0];\n      if (!resultsFile) {\n        reject(new Error('Results file not found'));\n        return;\n      }\n      \n      const results = JSON.parse(fs.readFileSync(resultsFile, 'utf-8'));\n      \n      // Clean up temporary files\n      fs.unlinkSync(tempDataFile);\n      fs.unlinkSync(scriptFile);\n      fs.unlinkSync(resultsFile);\n      \n      resolve(results);\n    });\n  });\n}\n\n// Main execution function\nasync function trainModel() {\n  try {\n    // Connect to LanceDB\n    const db = await lancedb.connect(lancedb_path);\n    \n    // Open the table\n    if (!db.tableNames().includes(table_name)) {\n      throw new Error(`Table ${table_name} not found in database`);\n    }\n    \n    const table = db.openTable(table_name);\n    \n    // Fetch data\n    const data = await table.toArray();\n    \n    // Prepare training data\n    const trainingData = data.map(row => ({\n      features: row[feature_column] || row.vector,\n      label: row[label_column]\n    }));\n    \n    // Train the model\n    const trainingResults = await trainWithPython(trainingData, model_type, model_params);\n    \n    // Create model directory if it doesn't exist\n    const modelDir = path.join(models_dir, model_id);\n    if (!fs.existsSync(modelDir)) {\n      fs.mkdirSync(modelDir, { recursive: true });\n    }\n    \n    // Generate version string\n    const version = new Date().toISOString().replace(/[:.]/g, '-');\n    \n    // Copy model file to models directory\n    const modelPath = path.join(modelDir, `${version}.pkl`);\n    fs.copyFileSync(trainingResults.model_file, modelPath);\n    \n    // Register model in LanceDB\n    const modelRegistryTable = db.tableNames().includes('model_registry') ?\n      db.openTable('model_registry') :\n      await db.createTable('model_registry', []);\n    \n    // Add model to registry\n    await modelRegistryTable.add([{\n      model_id: model_id,\n      version: version,\n      created_at: new Date().toISOString(),\n      model_type: model_type,\n      metrics: JSON.stringify(trainingResults.metrics),\n      model_path: modelPath,\n      metadata: JSON.stringify({\n        feature_column: feature_column,\n        label_column: label_column,\n        model_params: model_params,\n        training_data_table: table_name\n      }),\n      vector: trainingResults.model_vector\n    }]);\n    \n    // Clean up temporary model file\n    fs.unlinkSync(trainingResults.model_file);\n    \n    return {\n      status: 'success',\n      model_id: model_id,\n      version: version,\n      metrics: trainingResults.metrics,\n      model_path: modelPath\n    };\n  } catch (error) {\n    return {\n      status: 'error',\n      message: error.message,\n      stack: error.stack\n    };\n  }\n}\n\n// Execute the model training\nreturn trainModel();"
      },
      "id": "2fc99ebd-fc14-4c2a-a2f1-e7ebb0ace30a",
      "name": "Code",
      "type": "n8n-nodes-base.code",
      "typeVersion": 1,
      "position": [
        450,
        300
      ]
    },
    {
      "parameters": {},
      "id": "cf81ad7c-c773-41b1-a345-5f31f4b5f6c9",
      "name": "Respond to Webhook",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [
        650,
        300
      ]
    }
  ],
  "connections": {
    "Webhook": {
      "main": [
        [
          {
            "node": "Code",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code": {
      "main": [
        [
          {
            "node": "Respond to Webhook",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": true,
  "settings": {},
  "versionId": "7ed405f1-21bb-4f5f-b73f-0b15c2d72fa6",
  "id": "2",
  "meta": {
    "instanceId": "104a4d37d8df52d53fbaff292ea28e9406991bd34179d95537c3cb456b38d5bc"
  },
  "tags": [
    {
      "name": "MLOps",
      "id": "1"
    }
  ]
}
